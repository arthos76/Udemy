{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class 0 ---> [1,0,0]\n",
    "#class 1 ---> [0,1,0]\n",
    "#class 2 ---> [0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_object = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_object.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler_object.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler_object.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8,input_dim=4,activation=\"relu\"))\n",
    "model.add(Dense(8,input_dim=4,activation=\"relu\"))\n",
    "model.add(Dense(3,activation=\"softmax\")) #Proba to be on the groups\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer = \"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " - 1s - loss: 1.0994 - acc: 0.6500\n",
      "Epoch 2/150\n",
      " - 0s - loss: 1.0906 - acc: 0.6400\n",
      "Epoch 3/150\n",
      " - 0s - loss: 1.0823 - acc: 0.6200\n",
      "Epoch 4/150\n",
      " - 0s - loss: 1.0745 - acc: 0.5400\n",
      "Epoch 5/150\n",
      " - 0s - loss: 1.0658 - acc: 0.5700\n",
      "Epoch 6/150\n",
      " - 0s - loss: 1.0572 - acc: 0.5900\n",
      "Epoch 7/150\n",
      " - 0s - loss: 1.0484 - acc: 0.6400\n",
      "Epoch 8/150\n",
      " - 0s - loss: 1.0396 - acc: 0.6600\n",
      "Epoch 9/150\n",
      " - 0s - loss: 1.0308 - acc: 0.6600\n",
      "Epoch 10/150\n",
      " - 0s - loss: 1.0223 - acc: 0.6600\n",
      "Epoch 11/150\n",
      " - 0s - loss: 1.0140 - acc: 0.6600\n",
      "Epoch 12/150\n",
      " - 0s - loss: 1.0058 - acc: 0.6600\n",
      "Epoch 13/150\n",
      " - 0s - loss: 0.9975 - acc: 0.6600\n",
      "Epoch 14/150\n",
      " - 0s - loss: 0.9892 - acc: 0.6600\n",
      "Epoch 15/150\n",
      " - 0s - loss: 0.9815 - acc: 0.6600\n",
      "Epoch 16/150\n",
      " - 0s - loss: 0.9738 - acc: 0.6600\n",
      "Epoch 17/150\n",
      " - 0s - loss: 0.9660 - acc: 0.6600\n",
      "Epoch 18/150\n",
      " - 0s - loss: 0.9583 - acc: 0.6600\n",
      "Epoch 19/150\n",
      " - 0s - loss: 0.9513 - acc: 0.6500\n",
      "Epoch 20/150\n",
      " - 0s - loss: 0.9443 - acc: 0.6500\n",
      "Epoch 21/150\n",
      " - 0s - loss: 0.9374 - acc: 0.6500\n",
      "Epoch 22/150\n",
      " - 0s - loss: 0.9303 - acc: 0.6600\n",
      "Epoch 23/150\n",
      " - 0s - loss: 0.9232 - acc: 0.6600\n",
      "Epoch 24/150\n",
      " - 0s - loss: 0.9160 - acc: 0.6700\n",
      "Epoch 25/150\n",
      " - 0s - loss: 0.9089 - acc: 0.6200\n",
      "Epoch 26/150\n",
      " - 0s - loss: 0.9017 - acc: 0.6200\n",
      "Epoch 27/150\n",
      " - 0s - loss: 0.8948 - acc: 0.6100\n",
      "Epoch 28/150\n",
      " - 0s - loss: 0.8877 - acc: 0.6200\n",
      "Epoch 29/150\n",
      " - 0s - loss: 0.8809 - acc: 0.6500\n",
      "Epoch 30/150\n",
      " - 0s - loss: 0.8737 - acc: 0.6600\n",
      "Epoch 31/150\n",
      " - 0s - loss: 0.8665 - acc: 0.6600\n",
      "Epoch 32/150\n",
      " - 0s - loss: 0.8601 - acc: 0.6500\n",
      "Epoch 33/150\n",
      " - 0s - loss: 0.8521 - acc: 0.6500\n",
      "Epoch 34/150\n",
      " - 0s - loss: 0.8452 - acc: 0.6600\n",
      "Epoch 35/150\n",
      " - 0s - loss: 0.8381 - acc: 0.7200\n",
      "Epoch 36/150\n",
      " - 0s - loss: 0.8309 - acc: 0.7800\n",
      "Epoch 37/150\n",
      " - 0s - loss: 0.8237 - acc: 0.8500\n",
      "Epoch 38/150\n",
      " - 0s - loss: 0.8166 - acc: 0.8600\n",
      "Epoch 39/150\n",
      " - 0s - loss: 0.8098 - acc: 0.8400\n",
      "Epoch 40/150\n",
      " - 0s - loss: 0.8025 - acc: 0.8800\n",
      "Epoch 41/150\n",
      " - 0s - loss: 0.7955 - acc: 0.8900\n",
      "Epoch 42/150\n",
      " - 0s - loss: 0.7878 - acc: 0.8600\n",
      "Epoch 43/150\n",
      " - 0s - loss: 0.7806 - acc: 0.7400\n",
      "Epoch 44/150\n",
      " - 0s - loss: 0.7736 - acc: 0.6800\n",
      "Epoch 45/150\n",
      " - 0s - loss: 0.7663 - acc: 0.6500\n",
      "Epoch 46/150\n",
      " - 0s - loss: 0.7592 - acc: 0.6500\n",
      "Epoch 47/150\n",
      " - 0s - loss: 0.7519 - acc: 0.6500\n",
      "Epoch 48/150\n",
      " - 0s - loss: 0.7449 - acc: 0.6500\n",
      "Epoch 49/150\n",
      " - 0s - loss: 0.7381 - acc: 0.6500\n",
      "Epoch 50/150\n",
      " - 0s - loss: 0.7314 - acc: 0.6500\n",
      "Epoch 51/150\n",
      " - 0s - loss: 0.7246 - acc: 0.6500\n",
      "Epoch 52/150\n",
      " - 0s - loss: 0.7176 - acc: 0.6500\n",
      "Epoch 53/150\n",
      " - 0s - loss: 0.7108 - acc: 0.6500\n",
      "Epoch 54/150\n",
      " - 0s - loss: 0.7044 - acc: 0.6500\n",
      "Epoch 55/150\n",
      " - 0s - loss: 0.6973 - acc: 0.6500\n",
      "Epoch 56/150\n",
      " - 0s - loss: 0.6907 - acc: 0.6500\n",
      "Epoch 57/150\n",
      " - 0s - loss: 0.6841 - acc: 0.6500\n",
      "Epoch 58/150\n",
      " - 0s - loss: 0.6777 - acc: 0.6500\n",
      "Epoch 59/150\n",
      " - 0s - loss: 0.6712 - acc: 0.6500\n",
      "Epoch 60/150\n",
      " - 0s - loss: 0.6655 - acc: 0.6600\n",
      "Epoch 61/150\n",
      " - 0s - loss: 0.6594 - acc: 0.6800\n",
      "Epoch 62/150\n",
      " - 0s - loss: 0.6532 - acc: 0.7100\n",
      "Epoch 63/150\n",
      " - 0s - loss: 0.6474 - acc: 0.7400\n",
      "Epoch 64/150\n",
      " - 0s - loss: 0.6412 - acc: 0.7800\n",
      "Epoch 65/150\n",
      " - 0s - loss: 0.6354 - acc: 0.7500\n",
      "Epoch 66/150\n",
      " - 0s - loss: 0.6297 - acc: 0.7900\n",
      "Epoch 67/150\n",
      " - 0s - loss: 0.6241 - acc: 0.8000\n",
      "Epoch 68/150\n",
      " - 0s - loss: 0.6189 - acc: 0.7600\n",
      "Epoch 69/150\n",
      " - 0s - loss: 0.6129 - acc: 0.7400\n",
      "Epoch 70/150\n",
      " - 0s - loss: 0.6078 - acc: 0.7300\n",
      "Epoch 71/150\n",
      " - 0s - loss: 0.6025 - acc: 0.7100\n",
      "Epoch 72/150\n",
      " - 0s - loss: 0.5977 - acc: 0.6900\n",
      "Epoch 73/150\n",
      " - 0s - loss: 0.5930 - acc: 0.6800\n",
      "Epoch 74/150\n",
      " - 0s - loss: 0.5882 - acc: 0.6600\n",
      "Epoch 75/150\n",
      " - 0s - loss: 0.5833 - acc: 0.6600\n",
      "Epoch 76/150\n",
      " - 0s - loss: 0.5788 - acc: 0.6600\n",
      "Epoch 77/150\n",
      " - 0s - loss: 0.5743 - acc: 0.6700\n",
      "Epoch 78/150\n",
      " - 0s - loss: 0.5699 - acc: 0.6800\n",
      "Epoch 79/150\n",
      " - 0s - loss: 0.5656 - acc: 0.6900\n",
      "Epoch 80/150\n",
      " - 0s - loss: 0.5616 - acc: 0.7200\n",
      "Epoch 81/150\n",
      " - 0s - loss: 0.5571 - acc: 0.7500\n",
      "Epoch 82/150\n",
      " - 0s - loss: 0.5528 - acc: 0.7500\n",
      "Epoch 83/150\n",
      " - 0s - loss: 0.5486 - acc: 0.7300\n",
      "Epoch 84/150\n",
      " - 0s - loss: 0.5453 - acc: 0.7300\n",
      "Epoch 85/150\n",
      " - 0s - loss: 0.5415 - acc: 0.7200\n",
      "Epoch 86/150\n",
      " - 0s - loss: 0.5380 - acc: 0.7000\n",
      "Epoch 87/150\n",
      " - 0s - loss: 0.5345 - acc: 0.6900\n",
      "Epoch 88/150\n",
      " - 0s - loss: 0.5306 - acc: 0.7000\n",
      "Epoch 89/150\n",
      " - 0s - loss: 0.5268 - acc: 0.7200\n",
      "Epoch 90/150\n",
      " - 0s - loss: 0.5227 - acc: 0.7500\n",
      "Epoch 91/150\n",
      " - 0s - loss: 0.5192 - acc: 0.8100\n",
      "Epoch 92/150\n",
      " - 0s - loss: 0.5160 - acc: 0.8600\n",
      "Epoch 93/150\n",
      " - 0s - loss: 0.5124 - acc: 0.8900\n",
      "Epoch 94/150\n",
      " - 0s - loss: 0.5093 - acc: 0.9000\n",
      "Epoch 95/150\n",
      " - 0s - loss: 0.5058 - acc: 0.8900\n",
      "Epoch 96/150\n",
      " - 0s - loss: 0.5024 - acc: 0.8800\n",
      "Epoch 97/150\n",
      " - 0s - loss: 0.4990 - acc: 0.8400\n",
      "Epoch 98/150\n",
      " - 0s - loss: 0.4966 - acc: 0.7800\n",
      "Epoch 99/150\n",
      " - 0s - loss: 0.4936 - acc: 0.8000\n",
      "Epoch 100/150\n",
      " - 0s - loss: 0.4900 - acc: 0.8300\n",
      "Epoch 101/150\n",
      " - 0s - loss: 0.4868 - acc: 0.8600\n",
      "Epoch 102/150\n",
      " - 0s - loss: 0.4838 - acc: 0.8600\n",
      "Epoch 103/150\n",
      " - 0s - loss: 0.4808 - acc: 0.8300\n",
      "Epoch 104/150\n",
      " - 0s - loss: 0.4781 - acc: 0.8300\n",
      "Epoch 105/150\n",
      " - 0s - loss: 0.4748 - acc: 0.8800\n",
      "Epoch 106/150\n",
      " - 0s - loss: 0.4717 - acc: 0.8900\n",
      "Epoch 107/150\n",
      " - 0s - loss: 0.4689 - acc: 0.8900\n",
      "Epoch 108/150\n",
      " - 0s - loss: 0.4659 - acc: 0.8900\n",
      "Epoch 109/150\n",
      " - 0s - loss: 0.4628 - acc: 0.8900\n",
      "Epoch 110/150\n",
      " - 0s - loss: 0.4603 - acc: 0.8900\n",
      "Epoch 111/150\n",
      " - 0s - loss: 0.4574 - acc: 0.8900\n",
      "Epoch 112/150\n",
      " - 0s - loss: 0.4548 - acc: 0.8900\n",
      "Epoch 113/150\n",
      " - 0s - loss: 0.4519 - acc: 0.8900\n",
      "Epoch 114/150\n",
      " - 0s - loss: 0.4488 - acc: 0.9000\n",
      "Epoch 115/150\n",
      " - 0s - loss: 0.4461 - acc: 0.9200\n",
      "Epoch 116/150\n",
      " - 0s - loss: 0.4433 - acc: 0.9200\n",
      "Epoch 117/150\n",
      " - 0s - loss: 0.4418 - acc: 0.9000\n",
      "Epoch 118/150\n",
      " - 0s - loss: 0.4391 - acc: 0.8900\n",
      "Epoch 119/150\n",
      " - 0s - loss: 0.4366 - acc: 0.8900\n",
      "Epoch 120/150\n",
      " - 0s - loss: 0.4341 - acc: 0.8900\n",
      "Epoch 121/150\n",
      " - 0s - loss: 0.4314 - acc: 0.8900\n",
      "Epoch 122/150\n",
      " - 0s - loss: 0.4281 - acc: 0.9000\n",
      "Epoch 123/150\n",
      " - 0s - loss: 0.4256 - acc: 0.9100\n",
      "Epoch 124/150\n",
      " - 0s - loss: 0.4232 - acc: 0.9100\n",
      "Epoch 125/150\n",
      " - 0s - loss: 0.4207 - acc: 0.9100\n",
      "Epoch 126/150\n",
      " - 0s - loss: 0.4179 - acc: 0.9300\n",
      "Epoch 127/150\n",
      " - 0s - loss: 0.4151 - acc: 0.9300\n",
      "Epoch 128/150\n",
      " - 0s - loss: 0.4124 - acc: 0.9400\n",
      "Epoch 129/150\n",
      " - 0s - loss: 0.4097 - acc: 0.9400\n",
      "Epoch 130/150\n",
      " - 0s - loss: 0.4070 - acc: 0.9400\n",
      "Epoch 131/150\n",
      " - 0s - loss: 0.4045 - acc: 0.9400\n",
      "Epoch 132/150\n",
      " - 0s - loss: 0.4024 - acc: 0.9400\n",
      "Epoch 133/150\n",
      " - 0s - loss: 0.4003 - acc: 0.9300\n",
      "Epoch 134/150\n",
      " - 0s - loss: 0.3988 - acc: 0.9200\n",
      "Epoch 135/150\n",
      " - 0s - loss: 0.3964 - acc: 0.9200\n",
      "Epoch 136/150\n",
      " - 0s - loss: 0.3933 - acc: 0.9300\n",
      "Epoch 137/150\n",
      " - 0s - loss: 0.3892 - acc: 0.9400\n",
      "Epoch 138/150\n",
      " - 0s - loss: 0.3861 - acc: 0.9400\n",
      "Epoch 139/150\n",
      " - 0s - loss: 0.3834 - acc: 0.9500\n",
      "Epoch 140/150\n",
      " - 0s - loss: 0.3807 - acc: 0.9600\n",
      "Epoch 141/150\n",
      " - 0s - loss: 0.3786 - acc: 0.9600\n",
      "Epoch 142/150\n",
      " - 0s - loss: 0.3765 - acc: 0.9600\n",
      "Epoch 143/150\n",
      " - 0s - loss: 0.3740 - acc: 0.9600\n",
      "Epoch 144/150\n",
      " - 0s - loss: 0.3716 - acc: 0.9600\n",
      "Epoch 145/150\n",
      " - 0s - loss: 0.3683 - acc: 0.9600\n",
      "Epoch 146/150\n",
      " - 0s - loss: 0.3658 - acc: 0.9600\n",
      "Epoch 147/150\n",
      " - 0s - loss: 0.3634 - acc: 0.9600\n",
      "Epoch 148/150\n",
      " - 0s - loss: 0.3606 - acc: 0.9600\n",
      "Epoch 149/150\n",
      " - 0s - loss: 0.3578 - acc: 0.9600\n",
      "Epoch 150/150\n",
      " - 0s - loss: 0.3553 - acc: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6cc67b07b8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train,y_train,epochs=150,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            setosa  versicolor  virginica\n",
      "setosa          19           0          0\n",
      "versicolor       0          14          1\n",
      "virginica        0           0         16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Report the confusion matrix\n",
    "cm = pd.DataFrame(confusion_matrix(y_test.argmax(axis=1),predictions),columns= class_name,index=class_name)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\",cmap=\"coolwarm\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.93      0.97        15\n",
      "           2       0.94      1.00      0.97        16\n",
      "\n",
      "   micro avg       0.98      0.98      0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(classification_report(y_test.argmax(axis=1),predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.0\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test.argmax(axis=1),predictions) *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"myfirstmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model(\"myfirstmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
